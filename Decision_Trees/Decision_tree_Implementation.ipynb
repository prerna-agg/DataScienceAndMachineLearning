{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from sklearn import datasets\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pure node\n",
      "y_train [0]\n",
      "current entropy is 0.0\n",
      "1\n",
      "petal width (cm) 0.202437982551221\n",
      "\n",
      "pure node\n",
      "y_train [0 0 0]\n",
      "current entropy is 0.0\n",
      "3\n",
      "petal width (cm) 0.09769178693160412\n",
      "\n",
      "pure node\n",
      "y_train [0 0 0 0 0]\n",
      "current entropy is 0.0\n",
      "5\n",
      "petal width (cm) 0.036777106805558527\n",
      "\n",
      "pure node\n",
      "y_train [0 0 0 0 0]\n",
      "current entropy is 0.0\n",
      "5\n",
      "petal width (cm) 0.3171042163605767\n",
      "\n",
      "here\n",
      "y_train [0 0 2 0 1 0]\n",
      "current entropy is 1.2516291673878228\n",
      "6\n",
      "petal width (cm) 0\n",
      "\n",
      "here\n",
      "y_train [0 1 0 0 0 1 0 0]\n",
      "current entropy is 0.8112781244591328\n",
      "8\n",
      "petal width (cm) 0\n",
      "\n",
      "pure node\n",
      "y_train [0 0 0 0 0 0]\n",
      "current entropy is 0.0\n",
      "6\n",
      "petal width (cm) 0.2339774775966272\n",
      "\n",
      "here\n",
      "y_train [1 0 0]\n",
      "current entropy is 0.9182958340544896\n",
      "3\n",
      "petal width (cm) 0\n",
      "\n",
      "pure node\n",
      "y_train [0 0]\n",
      "current entropy is 0.0\n",
      "2\n",
      "petal width (cm) 0.2919693065629077\n",
      "\n",
      "here\n",
      "y_train [0 1 1 1]\n",
      "current entropy is 0.8112781244591328\n",
      "4\n",
      "petal width (cm) 0\n",
      "\n",
      "here\n",
      "y_train [1 2 1]\n",
      "current entropy is 0.9182958340544896\n",
      "3\n",
      "petal width (cm) 0\n",
      "\n",
      "here\n",
      "y_train [0 1 2 1 0 1 1]\n",
      "current entropy is 1.3787834934861756\n",
      "7\n",
      "petal width (cm) 0\n",
      "\n",
      "here\n",
      "y_train [1 1 2 2]\n",
      "current entropy is 1.0\n",
      "4\n",
      "petal width (cm) 0\n",
      "\n",
      "here\n",
      "y_train [2 1 1]\n",
      "current entropy is 0.9182958340544896\n",
      "3\n",
      "petal width (cm) 0\n",
      "\n",
      "here\n",
      "y_train [2 1 2 1 1]\n",
      "current entropy is 0.9709505944546686\n",
      "5\n",
      "petal width (cm) 0\n",
      "\n",
      "here\n",
      "y_train [2 1 2 1]\n",
      "current entropy is 1.0\n",
      "4\n",
      "petal width (cm) 0\n",
      "\n",
      "here\n",
      "y_train [2 1 2 1]\n",
      "current entropy is 1.0\n",
      "4\n",
      "petal width (cm) 0\n",
      "\n",
      "here\n",
      "y_train [2 2 2 1 2 2 1]\n",
      "current entropy is 0.863120568566631\n",
      "7\n",
      "petal width (cm) 0\n",
      "\n",
      "here\n",
      "y_train [2 1 2 2 2]\n",
      "current entropy is 0.7219280948873623\n",
      "5\n",
      "petal width (cm) 0\n",
      "\n",
      "here\n",
      "y_train [1 2 2 2 2]\n",
      "current entropy is 0.7219280948873623\n",
      "5\n",
      "petal width (cm) 0\n",
      "\n",
      "pure node\n",
      "y_train [1]\n",
      "current entropy is 0.0\n",
      "1\n",
      "petal width (cm) 0.09344283122106538\n",
      "\n",
      "here\n",
      "y_train [2 1 2 2 2 1 2]\n",
      "current entropy is 0.863120568566631\n",
      "7\n",
      "petal width (cm) 0\n",
      "\n",
      "here\n",
      "y_train [2 1 2]\n",
      "current entropy is 0.9182958340544896\n",
      "3\n",
      "petal width (cm) 0\n",
      "\n",
      "here\n",
      "y_train [2 1]\n",
      "current entropy is 1.0\n",
      "2\n",
      "petal width (cm) 0\n",
      "\n",
      "pure node\n",
      "y_train [1]\n",
      "current entropy is 0.0\n",
      "1\n",
      "petal width (cm) 0.22598245787871904\n",
      "\n",
      "pure node\n",
      "y_train [2 2 2]\n",
      "current entropy is 0.0\n",
      "3\n",
      "petal width (cm) 0.3279627978766033\n",
      "\n",
      "pure node\n",
      "y_train [2]\n",
      "current entropy is 0.0\n",
      "1\n",
      "petal width (cm) 0.1783904619724328\n",
      "\n",
      "pure node\n",
      "y_train [2]\n",
      "current entropy is 0.0\n",
      "1\n",
      "petal width (cm) 0.12666717642934383\n",
      "\n",
      "pure node\n",
      "y_train [2 2 2]\n",
      "current entropy is 0.0\n",
      "3\n",
      "petal width (cm) 0.269338481148821\n",
      "\n"
     ]
    }
   ],
   "source": [
    "current_entropy=entropy(x_train,y_train,len(x_train))\n",
    "\n",
    "CustomDecisionTreeClassifier(x_train,y_train,iris.feature_names,current_entropy,0,0,iris.feature_names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(x_train,y_train,totalDataPoints):\n",
    "    \n",
    "    count=np.unique(y_train,return_counts=True)\n",
    "    totalPoints= len(x_train)\n",
    "    \n",
    "    ent=0\n",
    "    \n",
    "    for i in range(len(count[0])):\n",
    "        ent=ent+-1*((count[1][i]/totalPoints)*(math.log(count[1][i]/totalPoints,2)))\n",
    "\n",
    "    return ent\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gain_ratio(x_train,y_train,selected_feature,previous_entropy):\n",
    "    \n",
    "    x=x_train[:,selected_feature]\n",
    "    x=np.sort(x)\n",
    "    \n",
    "    totalDataPoints=len(x)\n",
    "    \n",
    "    splitPoint=x[0]\n",
    "    \n",
    "    ele1=x[0]\n",
    "    \n",
    "    max_gain_ratio=0\n",
    "    gain_ratio=0\n",
    "    max_total_entropy=0\n",
    "    \n",
    "    for i in range(1,len(x)):\n",
    "        splitInfo=0\n",
    "        ele2=x[i]\n",
    "        mid=(ele1+ele2)/2\n",
    "        ele1=ele2\n",
    "        \n",
    "        x1=x[x<=mid]\n",
    "        \n",
    "        e1=entropy(x1,y_train[x<=mid],len(x1))\n",
    "        \n",
    "        if(len(x1)!=0):\n",
    "            splitInfo=splitInfo+ (-1)*((len(x1)/len(x))*(math.log(len(x1)/len(x),2)))\n",
    "        \n",
    "        x2=x[x>mid]\n",
    "        \n",
    "        e2=entropy(x2,y_train[x>mid],len(x2))\n",
    "        \n",
    "        if(len(x2)!=0):\n",
    "            splitInfo=splitInfo+ (-1)*((len(x2)/len(x))*(math.log(len(x2)/len(x),2)))\n",
    "        \n",
    "        totalEntropy = (len(x1)/totalDataPoints)*e1 + (len(x2)/totalDataPoints)*e2\n",
    "        \n",
    "        info_gain = abs(totalEntropy-previous_entropy)\n",
    "        \n",
    "        if splitInfo!=0:\n",
    "            gain_ratio = info_gain/splitInfo\n",
    "        \n",
    "        if(gain_ratio>max_gain_ratio):\n",
    "            max_gain_ratio=gain_ratio\n",
    "            splitPoint=mid\n",
    "            max_total_entropy=totalEntropy\n",
    "            \n",
    "#         print(totalEntropy)\n",
    "        \n",
    "        \n",
    "    \n",
    "    return max_gain_ratio,splitPoint,max_total_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CustomDecisionTreeClassifier(x_train,y_train,features,previous_entropy,selected_feature,previous_gain_ratio,f_name):\n",
    "   \n",
    "    if(len(set(y_train))==0):\n",
    "        return\n",
    "    \n",
    "    if len(set(y_train))==1:\n",
    "        print('pure node')\n",
    "        print('y_train',y_train)\n",
    "        print('current entropy is',entropy(x_train,y_train,len(x_train)))\n",
    "        print(len(x_train))\n",
    "        print(features[selected_feature],previous_gain_ratio)\n",
    "        print()\n",
    "        return\n",
    "    \n",
    "    if len(features)==0:\n",
    "        print('here')\n",
    "        print('y_train',y_train)\n",
    "        print('current entropy is',entropy(x_train,y_train,len(x_train)))\n",
    "        print(len(x_train))\n",
    "        print(f_name,previous_gain_ratio)\n",
    "        print()\n",
    "        return\n",
    "    \n",
    "   \n",
    "        \n",
    "    max_gain_ratio=0\n",
    "    selected_split_point=0\n",
    "    selected_feature=0\n",
    "    ent=0\n",
    "    for f in range(len(features)):\n",
    "        \n",
    "        gain_ratio_and_split_point = calculate_gain_ratio(x_train,y_train,f,previous_entropy)\n",
    "        gain_ratio=gain_ratio_and_split_point[0]\n",
    "        split_point=gain_ratio_and_split_point[1]\n",
    "#         print('split_point',split_point)\n",
    "        if max_gain_ratio<gain_ratio:\n",
    "            max_gain_ratio=gain_ratio\n",
    "            selected_feature=f\n",
    "            selected_split_point=split_point\n",
    "            ent=gain_ratio_and_split_point[2]\n",
    "            \n",
    "    \n",
    "    x1=len(x_train[x_train[:,selected_feature]<=split_point])\n",
    "    x2=len(x_train[x_train[:,selected_feature]>split_point])\n",
    "    f_name=features[selected_feature]\n",
    "    if(x1==0 or x2==0):\n",
    "        \n",
    "        if x1!=0:\n",
    "            CustomDecisionTreeClassifier(x_train[x_train[:,selected_feature]<=split_point],y_train[x_train[:,selected_feature]<=split_point],np.delete(features,selected_feature),ent,selected_feature,max_gain_ratio,f_name)\n",
    "        if x2!=0:\n",
    "            CustomDecisionTreeClassifier(x_train[x_train[:,selected_feature]>split_point],y_train[x_train[:,selected_feature]>split_point],np.delete(features,selected_feature),ent,selected_feature,max_gain_ratio,f_name)\n",
    "    else:\n",
    "        CustomDecisionTreeClassifier(x_train[x_train[:,selected_feature]<=split_point],y_train[x_train[:,selected_feature]<=split_point],features,ent,selected_feature,max_gain_ratio,f_name)\n",
    "        CustomDecisionTreeClassifier(x_train[x_train[:,selected_feature]>split_point],y_train[x_train[:,selected_feature]>split_point],features,ent,selected_feature,max_gain_ratio,f_name)\n",
    "            \n",
    "            \n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
